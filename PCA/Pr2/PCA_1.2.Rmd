---
title: "Principal component analysis - Practice 1.2"
author: "José Luis Romero Béjar"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  word_document:
    toc: yes
    toc_depth: '6'
  html_document:
    df_print: paged
    toc: yes
    toc_depth: 6
    number_sections: yes
    toc_float:
      collapsed: yes
      smooth_scroll: no
---
<style>
.math {
  font-size: 8.25pt;options(encoding = 'UTF-8')
}
</style>

<div style="text-align: justify">

© This material is licensed under a **Creative Commons CC BY-NC-ND** attribution which allows *works to be downloaded and shared with others, as long as they are referenced, but may not be modified in any way or used commercially*.


In this guide, a second example of dimensionality reduction in a dataset is performed using the R language. To carry out this practice you must download the following files available on the PRADO platform of the course:

+ *PCA_1.2.Rmd*
+ *DB_PCA_1.2.sav*

This brief guide is intended to familiarize the reader with the following:

+ Exploratory data analisys to identify outliers and not available data (NA).
+ Dealing with outliers: identification and decision making.
+ Dealing with not available data (NA): identification and decision making.
+ Principal component analysis: requirements, obtaining principal components, explained variance, **appropriate number of principal components**, graphical outputs, coordenates in the new reference system.



# **Loading packages and data set**

## Loading and installing R packages

The following source code module is responsible for loading, if they are already installed, all the packages that will be used in this R session. While an R package can be loaded at any time when it is to be used, it is advisable to optimize its calls with this code chunk at the beginning.

Loading a package into an R session **requires it to be already installed**. If it is not, the first step is to run the sentence:

*install.packages("name_of_the_library")*


```{r warning=FALSE, message=FALSE}

#########################################
# Loading necessary packages and reason #
#########################################

# This is an example of the first installation of a package
# Only runs once if the package is not installed
# Once it is installed this sentence has to be commented (not to run again)
# install.packages("summarytools")

# Package required to call 'freq' and 'descr' functions (descriptive statistics)
library(summarytools)

# Package required to call 'ggplot' function (graphical tools)
library(ggplot2)

# Package required to call 'ggarrange' function (graphical tools)
library(ggpubr)

# Package required to call 'read.spss' function (loading '.spss' data format)
library(foreign)

# Package required to call 'read_xlsx' function (loading '.xlsx' data format)
library(readxl)

# Package required to load the data set 'RBGlass1'
library(archdata)

# Package required to call 'cortest.bartlett' function
library(psych)

# Package required to call 'fviz_pca_var, fviz_pca_ind and fviz_pca' functions
library(factoextra)

# Package required to call 'scatterplot3d' function
library(scatterplot3d)

library(haven)

```

## Description of the data set *DB_PCA_1.2.sav*

The following code chunk shows how to load the dataset with IBMS SPSS format (.sav).

### IBM SPSS format *(.sav)*

```{r warning=FALSE, message=FALSE}
# Loading a .sav (IBM SPSS) file
# The output of this function is NOT a data.frame object
# Remember that package 'foreign' is required
data_spss<-read_spss("DB_PCA_1.2.sav")

# This sentence identifies the type of object that the identifier represents
class(data_spss)

```

The file *DB_PCA_1.2.sav* contains, among others, the variables *znac_def, zmortinf, zfertil, zinc_pob, rate_na, zurbana, zalfabet, zcaloría, zlog_pib, zpib_cap, zpoblac, zdensida*, which are the standardized variables of the original ones with the same label but without the initial *z*, and which respectively are the values for each country in the world of:

+ Births/Deaths Rate (nac_def)
+ Infant mortality: deaths per 1000 live births (mortinf)
+ Fertility: average number of children (fertile)
+ Population increase in annual % (inc_pop)
+ Birth rate per 1,000 inhabitants (tasa_na)
+ Inhabitants in cities in % (urban)
+ Literate People in % (alfabet)
+ Daily calorie intake (calories)
+ Log(10) of GDP_CAP (log_pib)
+ Gross domestic product per capita (gdp_cap)
+ Population in thousands (poblac)
+ Inhabitants per km2 (density)

# **Basic descriptive statistics**

In this section, a preliminary exploratory data analysis of the data set is performed. For this purpose, if the variable is **quantitative**, the basic **numerical descriptive statistics** and a representation of its **histogram, density and boxplot** are shown. On the other hand, for the  **categorical** variables their **frequency table** and a **sector and bar diagram** are provided.

## **Exploring** the data set

```{r warning=FALSE, message=FALSE}

# This line loads the variable names from this data.frame
# So that we can access by their name with no refer to the data.frame identifier
attach(data_spss)

# Retrieving the name of all variables
colnames(data_spss)

# Displaying a few records
head(data_spss, n=10)

# Displaying basic descriptives of variable 'Al'
summary(zlogden)


```

## **Descriptive analysis** (numerical and graphical)


### poblac - Population

```{r warning=FALSE, message=FALSE}

# Basic descriptive statistics
# Remember that package 'summarytools' is required
descr(poblac)

# Histogram, density and boxplot
# Remember that package 'ggplot2' is required
p1<-ggplot(data_spss,aes(x=poblac))+geom_density()+
  labs(title = "Density of poblac",x="poblac",y="Values")

p2<-ggplot(data_spss,aes(x=poblac))+geom_histogram()+
  labs(title = "Histogram of poblac",x="poblac",y="Values")

p3<-ggplot(data_spss,aes(x=poblac))+
  geom_boxplot(outlier.colour="red", outlier.shape=1,outlier.size=2)+
  coord_flip()+labs(title = "Boxplot of poblac",x="Values",y="")

# This function controls the graphical output device
# Remember that package 'ggpubr' is required
ggarrange(p1,p2,p3, nrow=1, common.legend = FALSE)

```

### **Assignment**

Replicates the previous output for the varaible *poblac* for variables *densidad, urbana, relig, espvidaf, espvidam, alfabet, inc_pob, mortinf, pib_cap, región, calorías, sida, tasa_nat, tasa_mor, tasasida, nac_def* and *fertilid*. It must be taken into account that variables *relig* and *región* are categorical. It implies that the previous output is not adequate (see the variable *site* in the file *PCA_1.1.Rmd* to proceed in the same way with these two variables).

### Variables selection

The data frame *data_spss* has 48 variables. For this illustration we are interested in the standardized variables whose labels begin with *z*. These variables are in the columns 32 to 46. 

Next code chunk defines a new data frame object with the only fifteen variables of interest for this illustration.

```{r warning=FALSE, message=FALSE}

# The first 31 variables are eliminated.
data_pca<-data_spss[,-(1:31)]

# The last two variables seem to be duplicates or with irrelevant information.
data_pca<-data_pca[,-(16:17)]


# The first three records in the database are displayed
head(data_pca,n=3)

```  

## **Not available data** (NA)

### Identification and treatment

**The decision for not available data is to replace them by the mean of their variable**. This decision has been made assuming that the behavior of the *NA* is totally random (this would have to be analyzed in depth to confirm this decision made). Perhaps it is not the best option, it depends on the problem under analysis and the data recorded, but it is a way to introduce the reader to **how to define functions in R language**.

The following source code defines the function *not_available* whose utility is to deal with not available data.


```{r warning=FALSE, message=FALSE}

# Construction of the function that handles missing values.
not_available<-function(data,na.rm=F){
  data[is.na(data)]<-mean(data,na.rm=T)
  data
}

# We call the not_available function for each variable in the database
data_pca$znac_def<-not_available(data_pca$znac_def)
data_pca$zmortinf<-not_available(data_pca$zmortinf)
data_pca$zfertil<-not_available(data_pca$zfertil)
data_pca$zinc_pob<-not_available(data_pca$zinc_pob)
data_pca$ztasa_na<-not_available(data_pca$ztasa_na)
data_pca$zurbana<-not_available(data_pca$zurbana)
data_pca$zespvida<-not_available(data_pca$zespvida)
data_pca$zalfabet<-not_available(data_pca$zalfabet)
data_pca$zcaloría<-not_available(data_pca$zcaloría)
data_pca$zlog_pib<-not_available(data_pca$zlog_pib)
data_pca$zpib_cap<-not_available(data_pca$zpib_cap)
data_pca$zpoblac<-not_available(data_pca$zpoblac)
data_pca$zdensida<-not_available(data_pca$zdensida)
data_pca$zlog_pob<-not_available(data_pca$zlog_pob)
data_pca$zlogden<-not_available(data_pca$zlogden)

# We view the data again
head(data_pca,n=3)

```


##  **Outliers**

### Identification 

This graphical output shows together the boxplots of all the quantitative variables. Since all the variables are standardized there is no problem with the scales.


```{r warning=FALSE, message=FALSE}

# Boxplots of all variables together
# This visualization is not the best due to the difference between the scales
boxplot(data_pca,main="Outliers",
        xlab="All explanatory variables",
        ylab="Values",
        col=c(1:15))

```

### Making decisions

From previous graphical outputs it is noticed the presence of outliers for several variables. It is relevant to take into account these values since multivariate methods, such as principal component analisis (PCA), are sensitive to this fact.

This is not a light topic and it should be analyzed outlier per outlier. However, since the objective of this guide is to introduce to the reader in this preliminary step of exploratory data analysis and data preparation, **the decision for outliers is to replace them by the mean of their variable**. Perhaps it is not the best option, it depends on the problem under analysis and the data recorded, but it is a way to introduce the reader to **how to define functions in R language**.

The following source code defines the function *outlier* whose utility is to deal with the univariate outliers.


```{r warning=FALSE, message=FALSE}

# Recursive function that modifies outliers by the mean of their variable
outlier<-function(data,na.rm=T){

  H<-1.5*IQR(data)
  data[data<quantile(data,0.25,na.rm = T)-H]<-NA
  data[data>quantile(data,0.75, na.rm = T)+H]<-NA
  data[is.na(data)]<-mean(data, na.rm = T)
  H<-1.5*IQR(data)

  if (TRUE %in% (data<quantile(data,0.25,na.rm = T)-H) |
      TRUE %in% (data>quantile(data,0.75,na.rm = T)+H))
    outlier(data)
  else

    return(data)

}

# This data.frame is to preserve original data once the outliers are modified
data_pca_aux<-data_pca

# Called to outlier function for each variable identified with outliers
data_pca_aux$znac_def<-outlier(data_pca_aux$znac_def)
data_pca_aux$zmortinf<-outlier(data_pca_aux$zmortinf)
data_pca_aux$zespvida<-outlier(data_pca_aux$zespvida)
data_pca_aux$zpib_cap<-outlier(data_pca_aux$zpib_cap)
data_pca_aux$zpoblac<-outlier(data_pca_aux$zpoblac)
data_pca_aux$zdensida<-outlier(data_pca_aux$zdensida)
data_pca_aux$zlog_pob<-outlier(data_pca_aux$zlog_pob)
data_pca_aux$zlogden<-outlier(data_pca_aux$zlogden)

# We compare the original data and the fixed ones with respective boxplots 
par(mfrow=c(1,2))
# Boxplot original data
boxplot(data_pca,main="Original data",
        xlab="All explanatory variables",
        ylab="z-values",
        col=c(1:15))
# Boxplot fixed data
boxplot(data_pca_aux,main="Data with no outliers",
        xlab="All explanatory variables",
        ylab="z-values",
        col=c(1:15))


```


# **Principal component analysis**

## Requirements

### Correlated variables

According to the numerical results below, it is observed that the data **are correlated** both **at the sample level** (see correlation matrix) and **at the populacion level** (Bartlett's sphericity test is significant).

```{r warning=FALSE, message=FALSE}

###############################
# Correlation at sample level #
###############################

# Are the variables correlated at sample level?
correlation_matrix<-cor(data_pca_aux)
correlation_matrix
det(correlation_matrix)

# It is noticed an important correlation between some variables
# For instance, sodium (NA) and antimony (Sb) or titanium (Ti) and iron (Fe)
cor(data_pca_aux$zalfabet,data_pca_aux$ztasa_na)


###################################
# Correlation at population level #
###################################

# Bartlett's sphericity test:
# This test checks whether the correlations are significantly different from 0
# The null hypothesis is H_0; det(R)=1 means the variables are uncorrelated 
# R denotes the correlation matrix
# cortest.bartlett function in the package pysch performs this test
# This function works with standardized data.

# Standardization
data_pca_aux_scale<-scale(data_pca_aux)

# Bartlett's sphericity test
cortest.bartlett(cor(data_pca_aux_scale))

```

### Absence of outliers

Done in **Section 2.4.2** in the data.frame *data_acp_aux*.

### Standardized data

It is not necessary, since the *prcomp* function that obtains the principal components standardizes the data on its own.


## Principal components

### Obtaining


```{r warning=FALSE, message=FALSE}

# The 'prcomp' function in the base R package performs this analysis
# Parameters 'scale' and 'center' are set to TRUE to consider standardized data
PCA<-prcomp(data_pca_aux, scale=T, center = T)

# The field 'rotation' of the 'PCA' object is a matrix 
# Its columns are the coefficients of the principal components
# Indicates the weight of each variable in the corresponding principal component
PCA$rotation

# Standard deviations of each principal component
PCA$sdev
```


Each principal component is obtained in a simple way as a linear combination of all the variables with the coefficients indicated by the columns of the rotation matrix.


### Explained variance rate

```{r warning=FALSE, message=FALSE}

# The function 'summary' applied to the 'PCA' object provides relevant information
# - Standard deviations of each principal component
# - Proportion of variance explained and cummulative variance
summary(PCA)

# The following graph shows the proportion of explained variance
Explained_variance <- PCA$sdev^2 / sum(PCA$sdev^2)

p1<-ggplot(data = data.frame(Explained_variance, pc = 1:15),
  aes(x = pc, y = Explained_variance, fill=Explained_variance )) +
  geom_col(width = 0.3) + scale_y_continuous(limits = c(0,0.6)) + theme_bw() +
  labs(x = "Principal component", y= "Proportion of variance")

# The following graph shows the proportion of cumulative explained variance
Cummulative_variance<-cumsum(Explained_variance)

p2<-ggplot( data = data.frame(Cummulative_variance, pc = 1:15),
  aes(x = pc, y = Cummulative_variance ,fill=Cummulative_variance )) +
  geom_col(width = 0.5) +  scale_y_continuous(limits = c(0,1)) + theme_bw() +
  labs(x = "Principal component",
       y = "Proportion of cumulative variance")

p1
p2

```


### Appropriate number of principal components

There are different methods:

+ 1.- **Elbow method** (Cuadras, 2007).
+ 2.- **At the discretion of the researcher** who chooses a minimum percentage of variance explained by the principal components (it is not reliable because it can give more than necessary).
+ 3.- **Rule of Abdi et al.** (2010). The variances explained by the principal components are averaged and those whose proportion of explained variance exceeds the mean are selected.

For this illustration, applying the rule of Abdi et al., only **four principal components are considered**, as can be deduced from the following code chunk.

```{r warning=FALSE, message=FALSE}

#######################
# Rule of Abdi et al. #
#######################

# Variances
PCA$sdev^2

# Average of variances
mean(PCA$sdev^2)

```


### PCA graphical outputs of interest 

#### Distances 


```{r warning=FALSE, message=FALSE}

# These graphical outputs show the projection of the variables in two dimensions
# Display the weight of the variable in the direction of the principal component 
p1<-fviz_pca_var(PCA,repel=TRUE,col.var="cos2",
                 legend.title="Distance", title="Variables")+theme_bw()

p2<-fviz_pca_var(PCA,axes=c(1,3),repel=TRUE,col.var="cos2",
                 legend.title="Distance", title="Variables")+theme_bw()

p3<-fviz_pca_var(PCA,axes=c(2,3),repel=TRUE,col.var="cos2",
                 legend.title="Distance", title="Variables")+theme_bw()

# Displaying graphics
p1
p2
p3

```



#### Observations and variance contribution


```{r warning=FALSE, message=FALSE}

# It is also possible to represent the observations
# As well as identify with colors those observations that explain the greatest 
# variance of the principal components
p1<-fviz_pca_ind(PCA,col.ind = "contrib", 
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel=TRUE,legend.title="Contrib.var", title="Records")+theme_bw()

p2<-fviz_pca_ind(PCA,axes=c(1,3),col.ind = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel=TRUE,legend.title="Contrib.var", title="Records")+theme_bw()

p3<-fviz_pca_ind(PCA,axes=c(2,3),col.ind = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel=TRUE,legend.title="Contrib.var", title="Records")+theme_bw()

# Displaying graphics
p1
p2
p3

```



#### Observations and variables with variance contribution



```{r warning=FALSE, message=FALSE}

# Joint representation of variables and observations
# Relates the possible relationships between the contributions of the records
# to the variances of the components and the weight of the variables in each 
# principal component

p1<-fviz_pca(PCA,alpha.ind ="contrib", col.var = "cos2",
         col.ind="seagreen",
         gradient.cols = c("#FDF50E", "#FD960E", "#FD1E0E"),
         repel=TRUE, legend.title="Distancia")+theme_bw()

p2<-fviz_pca(PCA,axes=c(1,3),alpha.ind ="contrib", 
         col.var = "cos2",col.ind="seagreen",
         gradient.cols = c("#FDF50E", "#FD960E", "#FD1E0E"),
         repel=TRUE, legend.title="Distancia")+theme_bw()

p3<-fviz_pca(PCA,axes=c(2,3),alpha.ind ="contrib", 
         col.var = "cos2",col.ind="seagreen",
         gradient.cols = c("#FDF50E", "#FD960E", "#FD1E0E"),
         repel=TRUE, legend.title="Distancia")+theme_bw()

# Displaying graphics
p1
p2
p3

```


#### Coordinates in the new reference system


Finally, since the object of this study was to reduce the dimension of the data set, it is possible to obtain **the coordinates of the original data in the new reference system**. In fact, they are stored since we used the prcomp function to create the PCA variable.

```{r warning=FALSE, message=FALSE}

head(PCA$x)

```

